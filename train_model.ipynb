{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V28",
      "mount_file_id": "1qPHg6wp0NnenpxPxIHJus9KCt10EJFnH",
      "authorship_tag": "ABX9TyOEorBVKR0n2mdI+8x+g5/A",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aditya-007/Load-forecasting/blob/main/train_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip show tensorflow"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DfIbinkGmVyb",
        "outputId": "b3bfa292-cafc-4d96-b812-2c4f612c9b55"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name: tensorflow\n",
            "Version: 2.15.0\n",
            "Summary: TensorFlow is an open source machine learning framework for everyone.\n",
            "Home-page: https://www.tensorflow.org/\n",
            "Author: Google Inc.\n",
            "Author-email: packages@tensorflow.org\n",
            "License: Apache 2.0\n",
            "Location: /usr/local/lib/python3.10/dist-packages\n",
            "Requires: absl-py, astunparse, flatbuffers, gast, google-pasta, grpcio, h5py, keras, libclang, ml-dtypes, numpy, opt-einsum, packaging, protobuf, setuptools, six, tensorboard, tensorflow-estimator, tensorflow-io-gcs-filesystem, termcolor, typing-extensions, wrapt\n",
            "Required-by: dopamine_rl, tensorflow-text, tf_keras\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "ev4TXzp3l5ZG"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "import argparse\n",
        "from keras.layers import Dense, Dropout\n",
        "from keras.layers import LSTM\n",
        "from keras.models import Sequential\n",
        "from keras.callbacks import LambdaCallback\n",
        "from utils import feature_extraction, split_features"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def build_single_lstm(layers):\n",
        "    model = Sequential()\n",
        "    model.add(LSTM(50, input_shape=(layers[1], layers[0]), return_sequences=False))\n",
        "    model.add(Dense(1, activation=\"relu\", kernel_initializer=\"uniform\"))\n",
        "    model.compile(loss=\"mse\", optimizer=\"rmsprop\", metrics=[\"accuracy\"])\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "DZrYSLTJomml"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_double_lstm(layers):\n",
        "    dropout = 0.2\n",
        "    model = Sequential()\n",
        "    model.add(LSTM(128, input_shape=(layers[1], layers[0]), return_sequences=True))\n",
        "    model.add(Dropout(dropout))\n",
        "    model.add(LSTM(64, input_shape=(layers[1], layers[0]), return_sequences=False))\n",
        "    model.add(Dropout(dropout))\n",
        "    model.add(Dense(16, activation=\"relu\", kernel_initializer=\"uniform\"))\n",
        "    model.add(Dense(1, activation=\"relu\", kernel_initializer=\"uniform\"))\n",
        "    model.compile(loss=\"mse\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
        "    return model"
      ],
      "metadata": {
        "id": "vYk0tLygopi2"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_architectures = {\n",
        "    \"single_lstm\": build_single_lstm,\n",
        "    \"double_lstm\": build_double_lstm,\n",
        "}"
      ],
      "metadata": {
        "id": "UBMW7q4hoqQM"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main(settings):\n",
        "    features, minima, maxima, scaling_parameter = feature_extraction(settings.dataset_dir)\n",
        "    window = 5\n",
        "    X_train, y_train, X_test, y_test = split_features(features[::-1], window)\n",
        "    print(\"X_train\", X_train.shape)\n",
        "    print(\"y_train\", y_train.shape)\n",
        "    print(\"X_test\", X_test.shape)\n",
        "    print(\"y_test\", y_test.shape)\n",
        "\n",
        "    json_logging_callback = LambdaCallback(\n",
        "        on_epoch_end=lambda epoch, logs: print(json.dumps({\n",
        "            \"epoch\": epoch,\n",
        "            \"loss\": logs[\"loss\"],\n",
        "            \"acc\": logs[\"acc\"],\n",
        "            \"val_loss\": logs[\"val_loss\"],\n",
        "            \"val_acc\": logs[\"val_acc\"],\n",
        "        })),\n",
        "    )\n",
        "\n",
        "    # figure out which model architecture to use\n",
        "    arch = settings.model_architecture\n",
        "    assert arch in model_architectures, \"Unknown model architecture '%s'.\" % arch\n",
        "    builder = model_architectures[arch]\n",
        "\n",
        "    # build and train the model\n",
        "    model = builder([len(features.columns), window, 1])\n",
        "    model.fit(\n",
        "        X_train,\n",
        "        y_train,\n",
        "        batch_size=settings.batch_size,\n",
        "        epochs=settings.epochs,\n",
        "        validation_split=settings.validation_split,\n",
        "        callbacks=[json_logging_callback],\n",
        "        verbose=0)\n",
        "\n",
        "    # serialize model to JSON\n",
        "    model_json = model.to_json()\n",
        "    with open(os.path.join(settings.output_dir, \"model-layout.json\"), \"w\") as json_file:\n",
        "        json_file.write(model_json)\n",
        "\n",
        "    # serialize weights to HDF5\n",
        "    model.save_weights(os.path.join(settings.output_dir, \"model-weights.h5\"))\n",
        "    print(\"Saved model to disk\")"
      ],
      "metadata": {
        "id": "YKskkY8vosYa"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def cli():\n",
        "    parser = argparse.ArgumentParser()\n",
        "    parser.add_argument(\"--epochs\", type=int, required=True)\n",
        "    parser.add_argument(\"--batch_size\", type=int, required=True)\n",
        "    parser.add_argument(\"--validation_split\", type=float, required=True)\n",
        "    parser.add_argument(\"--model_architecture\", type=str, required=True, help=\"'single_lstm' or 'double_lstm'\")\n",
        "    parser.add_argument(\"--dataset_dir\", type=str, default=\"/valohai/inputs/dataset\")\n",
        "    parser.add_argument(\"--output_dir\", type=str, default=\"/valohai/outputs\")\n",
        "    settings = parser.parse_args()\n",
        "    main(settings)"
      ],
      "metadata": {
        "id": "HsC-O45how_G"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    cli()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 196
        },
        "id": "yY4lqNpCozWF",
        "outputId": "b6f0d368-75ca-46c1-b5a7-4d72af4cf3fb"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "usage: colab_kernel_launcher.py [-h] --epochs EPOCHS --batch_size BATCH_SIZE --validation_split\n",
            "                                VALIDATION_SPLIT --model_architecture MODEL_ARCHITECTURE\n",
            "                                [--dataset_dir DATASET_DIR] [--output_dir OUTPUT_DIR]\n",
            "colab_kernel_launcher.py: error: the following arguments are required: --epochs, --batch_size, --validation_split, --model_architecture\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "SystemExit",
          "evalue": "2",
          "traceback": [
            "An exception has occurred, use %tb to see the full traceback.\n",
            "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py:3561: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
            "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
          ]
        }
      ]
    }
  ]
}