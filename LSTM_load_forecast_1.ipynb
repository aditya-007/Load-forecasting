{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyP8syo7pOB1T0XEe6kDIKuK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aditya-007/Load-forecasting/blob/main/LSTM_load_forecast_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "77MNvolGA_JB"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM, Dense, Dropout\n",
        "from keras.optimizers import Adam\n",
        "from sklearn.metrics import mean_squared_error\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('ercot-dataset.csv')\n",
        "\n",
        "# Drop the 'Date' column since it is not needed for modeling\n",
        "data_cleaned = data.drop(['Date'], axis=1)\n",
        "\n",
        "# Display the first few rows and the column names to understand the dataset\n",
        "data.head(), data.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Lxgj0dNBKxR",
        "outputId": "2b888638-e1ff-46e6-e1f7-4651469de45f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(              Date  DryBulb  DewPnt  WetBulb  Humidity  ElecPrice  Day  Month  \\\n",
              " 0  01/01/2006 0:30     23.9   21.65    22.40      87.5      19.67    1      1   \n",
              " 1  01/01/2006 1:00     23.9   21.70    22.40      88.0      18.56    1      1   \n",
              " 2  01/01/2006 1:30     23.8   21.65    22.35      88.0      19.09    1      1   \n",
              " 3  01/01/2006 2:00     23.7   21.60    22.30      88.0      17.40    1      1   \n",
              " 4  01/01/2006 2:30     23.7   21.60    22.30      88.0      17.00    1      1   \n",
              " \n",
              "    Year  Minutes     SYSLoad  \n",
              " 0  2006       30  8013.27833  \n",
              " 1  2006       60  7726.89167  \n",
              " 2  2006       90  7372.85833  \n",
              " 3  2006      120  7071.83333  \n",
              " 4  2006      150  6865.44000  ,\n",
              " Index(['Date', 'DryBulb', 'DewPnt', 'WetBulb', 'Humidity', 'ElecPrice', 'Day',\n",
              "        'Month', 'Year', 'Minutes', 'SYSLoad'],\n",
              "       dtype='object'))"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalize the dataset using MinMaxScaler\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "data_scaled = scaler.fit_transform(data_cleaned)\n",
        "\n",
        "# Define the target variable (SYSLoad) and features (everything else)\n",
        "target_index = data.columns.get_loc('SYSLoad') - 1 # Adjusted due to dropped Date column"
      ],
      "metadata": {
        "id": "TmQ2vRShClYs"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create sequences for LSTM model input\n",
        "def create_sequences_lstm(data, target_index, time_step):\n",
        "    X, Y = [], []\n",
        "    for i in range(len(data) - time_step):\n",
        "        X.append(data[i:i+time_step, :])  # All features over the time step\n",
        "        Y.append(data[i+time_step, target_index])  # Target value at the next time step\n",
        "    return np.array(X), np.array(Y)\n",
        "\n",
        "# Define a time step (how many previous data points to consider)\n",
        "time_step = 60\n",
        "\n",
        "# Create the sequences\n",
        "X, Y = create_sequences_lstm(data_scaled, target_index, time_step)\n"
      ],
      "metadata": {
        "id": "3_DZ89QnCwuV"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split data into training and testing sets (80% train, 20% test)\n",
        "train_size = int(len(X) * 0.8)\n",
        "X_train, X_test = X[:train_size], X[train_size:]\n",
        "Y_train, Y_test = Y[:train_size], Y[train_size:]\n",
        "\n",
        "# Check the shapes of the prepared training and test sets\n",
        "X_train.shape, X_test.shape, Y_train.shape, Y_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CEcguTxLC6i3",
        "outputId": "5bfe0522-046d-489a-cf50-4f1928dc815e"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((70070, 60, 10), (17518, 60, 10), (70070,), (17518,))"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to build LSTM1, LSTM2, or LSTM3\n",
        "def build_lstm_model(model_type, time_step, input_dim):\n",
        "    model = Sequential()\n",
        "\n",
        "    if model_type == 'LSTM1':\n",
        "        # LSTM1 (Simple Model): One LSTM layer with 50 units\n",
        "        model.add(LSTM(units=50, return_sequences=False, input_shape=(time_step, input_dim)))\n",
        "\n",
        "    elif model_type == 'LSTM2':\n",
        "        # LSTM2 (My Complex Model): Two LSTM layers with 100 and 50 units\n",
        "        model.add(LSTM(units=100, return_sequences=True, input_shape=(time_step, input_dim)))\n",
        "        model.add(LSTM(units=50, return_sequences=False))\n",
        "\n",
        "    elif model_type == 'LSTM3':\n",
        "        # LSTM3 (Proposed Complex Model): Two LSTM layers with Dropout and ReLU activation\n",
        "        model.add(LSTM(units=128, return_sequences=True, input_shape=(time_step, input_dim)))\n",
        "        model.add(Dropout(0.2))  # Dropout after the first LSTM layer\n",
        "        model.add(LSTM(units=64, return_sequences=False))\n",
        "        model.add(Dropout(0.2))  # Dropout after the second LSTM layer\n",
        "        model.add(Dense(units=64, activation='relu'))  # Dense layer with ReLU activation\n",
        "\n",
        "    # Output layer for SYSLoad prediction\n",
        "    model.add(Dense(units=1))\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(optimizer=Adam(), loss='mean_squared_error')\n",
        "\n",
        "    return model\n",
        "\n",
        "# Select model type ('LSTM1', 'LSTM2', 'LSTM3')\n",
        "model_type = 'LSTM3'  # You can change this to 'LSTM1' or 'LSTM2'\n",
        "\n",
        "# Build the selected model\n",
        "input_dim = X_train.shape[2]  # Number of features (input dimensions)\n",
        "model = build_lstm_model(model_type, time_step, input_dim)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rEIa6TBWDFRc",
        "outputId": "4ed6603e-efde-4389-d4c4-61b0208fbf24"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model on the training set\n",
        "history = model.fit(X_train, Y_train, epochs=10, batch_size=64, validation_data=(X_test, Y_test), verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SQg3hlyZDKmS",
        "outputId": "b36dd484-3011-4039-e8bb-e17aaaebfdbd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m1095/1095\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m227s\u001b[0m 207ms/step - loss: 0.0024 - val_loss: 6.8193e-04\n",
            "Epoch 2/10\n",
            "\u001b[1m1095/1095\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m216s\u001b[0m 197ms/step - loss: 9.8342e-04 - val_loss: 4.0501e-04\n",
            "Epoch 3/10\n",
            "\u001b[1m1095/1095\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m264s\u001b[0m 199ms/step - loss: 5.6683e-04 - val_loss: 2.1040e-04\n",
            "Epoch 4/10\n",
            "\u001b[1m1095/1095\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m262s\u001b[0m 199ms/step - loss: 4.3357e-04 - val_loss: 3.2684e-04\n",
            "Epoch 5/10\n",
            "\u001b[1m1095/1095\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m259s\u001b[0m 197ms/step - loss: 3.6891e-04 - val_loss: 3.5423e-04\n",
            "Epoch 6/10\n",
            "\u001b[1m 880/1095\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m39s\u001b[0m 184ms/step - loss: 3.0859e-04"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions on the training and testing sets\n",
        "train_predict = model.predict(X_train)\n",
        "test_predict = model.predict(X_test)"
      ],
      "metadata": {
        "id": "Z_wT8x75HxMr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Inverse transform the predictions and the actual values to get the original scale\n",
        "train_predict = scaler.inverse_transform(\n",
        "    np.concatenate((np.zeros((train_predict.shape[0], data_cleaned.shape[1] - 1)), train_predict), axis=1)\n",
        ")[:, -1]  # We add back the other features with zeros before inverse transforming\n",
        "\n",
        "test_predict = scaler.inverse_transform(\n",
        "    np.concatenate((np.zeros((test_predict.shape[0], data_cleaned.shape[1] - 1)), test_predict), axis=1)\n",
        ")[:, -1]\n",
        "\n",
        "# Similarly, inverse transform the actual SYSLoad values for Y_train and Y_test\n",
        "Y_train_original = scaler.inverse_transform(\n",
        "    np.concatenate((np.zeros((Y_train.shape[0], data_cleaned.shape[1] - 1)), Y_train.reshape(-1, 1)), axis=1)\n",
        ")[:, -1]\n",
        "\n",
        "Y_test_original = scaler.inverse_transform(\n",
        "    np.concatenate((np.zeros((Y_test.shape[0], data_cleaned.shape[1] - 1)), Y_test.reshape(-1, 1)), axis=1)\n",
        ")[:, -1]"
      ],
      "metadata": {
        "id": "Pw_vLHqsIBj_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def mean_absolute_percentage_error(y_true, y_pred):\n",
        "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
        "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
        "\n",
        "# Calculate the Mean Absolute Percentage Error (MAPE) for training and testing sets\n",
        "test_mape = mean_absolute_percentage_error(Y_test_original, test_predict)\n",
        "\n",
        "test_mse = mean_squared_error(Y_test_original, test_predict)\n",
        "\n",
        "print(f\"Test MAPE: {test_mape:.2f}%\")\n",
        "print(f\"Test MSE: {test_mse:.2f}\")"
      ],
      "metadata": {
        "id": "zs1PWPVLUYf2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the first 24 actual vs predicted values for the training set\n",
        "plt.figure(figsize=(14, 6))\n",
        "plt.plot(Y_train_original[:48], label='Actual SYSLoad (Train)', color=\"blue\")\n",
        "plt.plot(train_predict[:48], label='Predicted SYSLoad (Train)', color=\"red\")\n",
        "plt.title('Training Set: Actual vs Predicted SYSLoad (First 24 Points)')\n",
        "plt.xlabel('Time Steps')\n",
        "plt.ylabel('SYSLoad')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Plot the first 24 actual vs predicted values for the testing set\n",
        "plt.figure(figsize=(14, 6))\n",
        "plt.plot(Y_test_original[:48], label='Actual SYSLoad (Test)', color=\"blue\")\n",
        "plt.plot(test_predict[:48], label='Predicted SYSLoad (Test)', color=\"red\")\n",
        "plt.title('Testing Set: Actual vs Predicted SYSLoad (First 24 Points)')\n",
        "plt.xlabel('Time Steps')\n",
        "plt.ylabel('SYSLoad')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "WvVMLKjqIHHY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}