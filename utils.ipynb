{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO/GPHGLiCvigdUcrhaTdRt",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aditya-007/Load-forecasting/blob/main/utils.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "7BdXhl3jkL2s"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import glob\n",
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_dataframe(dataset_path):\n",
        "    \"\"\"\n",
        "    :param dataset_path: Path to dataset as a .csv file\n",
        "    :return: Panda DataFrame\n",
        "    \"\"\"\n",
        "\n",
        "    # use the csv first file in the dataset directory\n",
        "    dataset_path = 'ercot-dataset.csv'\n",
        "\n",
        "    my_data = pd.read_csv(dataset_path, error_bad_lines=False)\n",
        "    df = pd.DataFrame(my_data)\n",
        "\n",
        "    column_names = list(df)\n",
        "    if 'Demand' in column_names:\n",
        "        # RTE dataset format\n",
        "        df = df.filter(items=['Day', 'Month', 'Hours', 'Temperature', 'Demand'])\n",
        "        return df, 'rte'\n",
        "    elif 'SYSLoad' in column_names:\n",
        "        # ERCOT dataset format.\n",
        "        df = df.filter(items=['Day', 'Month', 'Minutes', 'SYSLoad'])\n",
        "        return df, 'ercot'\n",
        "    else:\n",
        "        raise Exception('Unknown dataset format with columns: {}'.format(column_names))"
      ],
      "metadata": {
        "id": "ld1esfT-ke8e"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def feature_extraction(dataset_dir):\n",
        "    df, dataset_format = get_dataframe(dataset_dir)\n",
        "\n",
        "    values = df.values\n",
        "    minima = np.amin(values[:, -1])\n",
        "    maxima = np.amax(values[:, -1])\n",
        "    scaling_parameter = maxima - minima\n",
        "\n",
        "    if dataset_format == 'rte':\n",
        "        values[:, 0] = (values[:, 0] - np.amin(values[:, 0])) / (np.amax(values[:, 0]) - np.amin(values[:, 0]))\n",
        "        values[:, 1] = (values[:, 1] - np.amin(values[:, 1])) / (np.amax(values[:, 1]) - np.amin(values[:, 1]))\n",
        "        values[:, 2] = (values[:, 2] - np.amin(values[:, 2])) / (np.amax(values[:, 2]) - np.amin(values[:, 2]))\n",
        "        values[:, 3] = (values[:, 3] - np.amin(values[:, 3])) / (np.amax(values[:, 3]) - np.amin(values[:, 3]))\n",
        "        values[:, 4] = (values[:, 4] - minima) / scaling_parameter\n",
        "    elif dataset_format == 'ercot':\n",
        "        values[:, 0] = (values[:, 0] - np.amin(values[:, 0])) / (np.amax(values[:, 0]) - np.amin(values[:, 0]))\n",
        "        values[:, 1] = (values[:, 1] - np.amin(values[:, 1])) / (np.amax(values[:, 1]) - np.amin(values[:, 1]))\n",
        "        values[:, 2] = (values[:, 2] - np.amin(values[:, 2])) / (np.amax(values[:, 2]) - np.amin(values[:, 2]))\n",
        "        values[:, 3] = (values[:, 3] - minima) / scaling_parameter\n",
        "\n",
        "    df = pd.DataFrame(values)\n",
        "    return df, minima, maxima, scaling_parameter"
      ],
      "metadata": {
        "id": "xEChk-FGkjsB"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def split_features(features_data_frame, seq_len):\n",
        "    amount_of_features = len(features_data_frame.columns)\n",
        "    data = features_data_frame.as_matrix()\n",
        "    sequence_length = seq_len + 1\n",
        "    result = []\n",
        "    for index in range(len(data) - sequence_length):\n",
        "        result.append(data[index: index + sequence_length])\n",
        "\n",
        "    result = np.array(result)\n",
        "    row = round(0.8 * result.shape[0])\n",
        "    train = result[:int(row), :]\n",
        "    x_train = train[:, :-1]\n",
        "    y_train = train[:, -1][:, -1]\n",
        "    x_test = result[int(row):, :-1]\n",
        "    y_test = result[int(row):, -1][:, -1]\n",
        "    x_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1], amount_of_features))\n",
        "    x_test = np.reshape(x_test, (x_test.shape[0], x_test.shape[1], amount_of_features))\n",
        "    return [x_train, y_train, x_test, y_test]"
      ],
      "metadata": {
        "id": "OUkhwHqqko4T"
      },
      "execution_count": 4,
      "outputs": []
    }
  ]
}